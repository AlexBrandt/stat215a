\documentclass{article}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

\usepackage{geometry}
\geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
\usepackage{fancyhdr}
\pagestyle{fancy}
\setlength{\parskip}{\smallskipamount}
\setlength{\parindent}{0pt}
\usepackage{amsthm}
\usepackage{amsmath}

\DeclareMathOperator*{\argmax}{arg\,max}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

\title{Homework 4}

\author{Alexander Brandt\\STAT 215A}

\maketitle

\section{Classification}

\subsection*{7.B.1}

\subsubsection*{a}

True: since from the definition of the CDF/PDF relationship:
\[\frac{\partial \Phi(x)}{\partial x} = \phi(x) \]
\subsubsection*{b}
True: again, this is a basic CDF/PDF relationship:
\[ \int_{-\infty}^{x} \phi(z) dz = \Phi(x) \]
\subsubsection*{c}
False: this is a basic calculus definition:
\[ \int_{x}^{x} \phi(z) dz = 0 \]
\subsubsection*{d}
True: From above, and part e:
\[ \int_{x}^{x} \phi(z) dz + \int_{-\infty}^{x} \phi(z) dz = 0 + \Phi(x)\]
\subsubsection*{e}
True:  Basic CDF/PDF relationship:
\[ \int_{-\infty}^{x} \phi(z) dz = \Phi(x) \]
\subsubsection*{f}
True:  Given CDF/PDF relationship:
\begin{align*}
P( x < Z < x+h) &= \lim_{x \to h} \int_{x}^{x+h} \phi(z) dz \\
&= \Phi(x+h) - \Phi(x)
\end{align*}
And basic calculus:
\[\lim_{x \to h} \frac{\Phi(x+h) - \Phi(x)}{h} = \phi(x) \]
Thus:
\[P( x < Z < x+h) = h \phi(x) \]
\subsection*{7.B.2}
\subsubsection*{a}
\(X_i\) is a column vector of 1 (the intercept), the educational level in years
of school the individual has attended, the income level of the individual in dollars,
and the gender of the individual (1 for male, 0 for female).  \(\beta_i\) is a column
vector of the weights associated with for the probit model.
\subsubsection*{b}
Random and Latent
\subsubsection*{c}
\(U_i\) is i.i.d. \(N(0, 1)\), and independent of the prediction variables.
\subsubsection*{d}
The log likihood function is a sum with one term for each subject.
\subsection{}
False.
\begin{align*}
\text{Difference} &= \Phi(X_{Harry}'\beta) - \Phi(X_{George}'\beta)\\
&= \Phi(.29) - \Phi(.19)\\
&= 3.87\%
\end{align*}
\section*{7.B.3}
I think I will be using \(x_i\) in the opposite orientation that the authors of the paper do.
\subsection*{Proof of 5.1}
Given \( (X_i' X_i)^{-1} = (X'X - x_i x_i')^{-1} \), and the Sherman Morrison
formula:
\begin{align*}
(X_i' X_i)^{-1} &= (X' X)^{-1} + \frac{(X' X)^{-1} x_i x_i' (X' X)^{-1}}{1 - x_i' X^{-1} x_i}\\
&= (X' X)^{-1} + \frac{(X' X)^{-1} x_i x_i' (X' X)^{-1}}{1 - h_i}
\end{align*}
\subsection*{Proof of 5.5}
Continuing from above:
\begin{align*}
\hat{\beta_i} &= (X_i' X_i)^{-1}(X'Y - x_i y_i)\\
&= \left[(X'X)^{-1} + \frac{(X' X)^{-1} x_i x_i' (X' X)^{-1}}{1 - h_i}\right](X'Y - x_i y_i)\\
&= (X' X)^{-1} X' Y - (X' X)^{-1} x_i y_i + \frac{(X' X)^{-1} x_i x_i' X' Y}{1 - h_i} - \frac{(X' X)^{-1} x_i x_i' x_i y_i}{1 - h_i}\\
&= \hat{\beta} - \frac{(X' X)^{-1} x_i}{1 - h_i}\left[y_i(1 - h_i) - x_i' \hat{\beta} + h_i y_i \right]\\
&= \hat{\beta} - \frac{(X' X)^{-1} x_i}{1 - h_i}\left[y_i - x_i' \hat{\beta}\right]\\
&= \hat{\beta} - \frac{(X' X)^{-1} x_i r_i}{1 - h_i}\\
\hat{\beta} - \hat{\beta_i} &= \frac{(X' X)^{-1} x_i r_i}{1 - h_i}
\end{align*}
I found this proof to be tricky, so I spent a lot of time reading through linear
algebra/linear regression texts.  In particular Linear Regresion Analysis by Seber and Lee (2003), especially Chapter 10, we really helpful in helping me complete these proofs.
\end{document}
